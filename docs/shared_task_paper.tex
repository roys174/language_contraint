\documentclass[11pt]{article}
\usepackage{eacl2017}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym,xcolor}

% \eaclfinalcopy % Uncomment this line for the final submission
%\def\eaclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
% Editing macros
\newcommand{\my}[1]{\footnote{\color{red}{\textbf{#1}}}}

\newcommand{\ms}[1]{{\color{cyan}\{\textit{#1}\}$_{ms}$}}
\newcommand{\roy}[1]{\footnote{\color{red}{\textbf{Roy: #1}}}}
\newcommand{\royb}[2]{{\color{red}{\sout{#1}}}{\color{green}{#2}}}
\newcommand{\royc}[3]{\royb{#1}{#2}\roy{#3}}
\newcommand{\yc}[1]{{\color{bblue}\{\textit{#1}\}$_{yc}$}}

\title{Story Cloze task -- UW System}

\author{Roy Schwartz\\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And	
  Maarten Sap \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Taking part in the LSDSem `17 shared task, we describe our system.

\end{abstract}

\section{Introduction}
% Describe the overall landscape of the problem
%  - Commonsense knowledge
%  - Script Learning
%  - 

Learning of commonsense knowledge is one of AI's biggest challenges, since it is not usually found in knowledge bases.
Coming up with the right types of data to analyze has been hard, and models are also not working well.

One particular type of commonsense knowledge that has gotten attention is story understanding \cite{??}. Stories have narratives that require understanding of how events typically flow and of what events are coherent after others.
Related to understanding event sequences is script learning, which focuses on stereotypical chains of events.

% Mention the specific purpose of the shared task (i.e. from the website)
The 2017 LSD Sem Shared Task provide a testbed to further commonsense story understanding: the \textit{Story Cloze} task \cite{Mostafazadeh:2016}. It was specifically designed for the purpose of facilitating the learning of commonsense knowledge. The task consist of finding the \textit{corrent} ending to four sentence short stories, out of two possible endings. 
With the two-ending stories, Mostafazadeh, et al. ~(2016)\nocite{Mostafazadeh:2016} also released nearly $100$k five-sentence short stories, to facilitate learning of commonsense narratives.

% Last paragraph should be a quick description of our system.
In this paper, we describe the system submission from the University of Washington NLP group (UW NLP).
We implement a simple classifier that uses surface features as well as language model features. Using the Shared Task test set, we achieve $75.1\%$ accuracy.

\section{System Description}
%% Explain that we have two sets of features, style and language.
%% Maybe mention here that we're doing training on validation set ?
In our system, we implement a simple linear classifier to choose between the \textit{correct} and \textit{incorrect} endings.
% \section{Features}
Specifically, we use two types of features (described in below), designed to capture different dimensions of the problem. We use \textit{stylistic} features to capture differences in writing between ``coherent'' endings and ``incoherent'' ones. We opt for \textit{language model} features to leverage corpus level word distributions, specifically longer term sequence probabilities.

\ms{Some info about training, etc.}

\subsection{Stylistic Features}
%% take stuff from the paper
In our classification task, we add the following features to capture style differences between the two endings:
\begin{itemize}
\item\textit{\textbf{Length}.} The number of words in the sentence.
\item\textit{\textbf{Word n-grams.}} We use sequences of 1-5 words. Following \cite{Tsur:2010,Schwartz:2013}, we distinguish between high frequency and low frequency words. 
Specifically, we replace content words, which are often low frequency, with their part-of-speech tags (Nouns, Verbs, Adjectives and Adverbs).
\item\textit{\textbf{Character n-grams.}} Character n-grams are useful features in author style \cite{Stamatatos:2009} or language identification \cite{lui2011cross}.
We use character 4-grams.
\end{itemize}

\subsection{Language Model Features}
%% take the RLM paragraph from the paper
In addition to stylistic features, we experiment with state-of-the-art text comprehension models, specifically a recurrent language model (RLM, Mikolov, et al. (2010)\nocite{mikolov2010recurrent}).
We train the RLM using a single-layer LSTM \cite{hochreiter1997long} of hidden dimension $h=512$.
We use the ROC Stories for training, setting aside $10\%$ for validation of the language model. 
We replace all words occurring less than 3 times by a special out-of-vocabulary character, yielding a vocabulary size of $|V|=$21,582.
Only during training, we apply a dropout rate of 60\% while running the LSTM over all 5 sentences of the stories. 
Using AdamOptimizer \cite{kingma2014adam} and a learning rate of $\eta=.001$, we train with backpropagation on cross-entropy. % minibatches of $50$ stories.
\section{Results \& Discussion}
% Show results

% ablation study? Table 2 from the paper sort of?

\section{Conclusion}

% Our system makes use of knowledge brought to us by the constrained writing literature (?)
% talk about how we use state-of-the-art language modelling tools.
% We achieve $75.1\%$ which is ranked XXth in the ongoing codalab competition.

\bibliography{acl2017}
\bibliographystyle{eacl2017}


\end{document}